{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting caption.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile caption.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import load\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 34\n",
    "\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "\n",
    "filename = \"C:/Users/Laxmi/Desktop/Flickr Dataset/Flickr dataset/Flickr8k.token.txt\"\n",
    "# load descriptions\n",
    "doc = load_doc(filename)\n",
    "\n",
    "\n",
    "def load_descriptions(doc):\n",
    "\tmapping = dict()\n",
    "\t# process lines\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\tif len(line) < 2:\n",
    "\t\t\tcontinue\n",
    "\t\t# take the first token as the image id, the rest as the description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# extract filename from image id\n",
    "\t\timage_id = image_id.split('.')[0]\n",
    "\t\t# convert description tokens back to string\n",
    "\t\timage_desc = ' '.join(image_desc)\n",
    "\t\t# create the list if needed\n",
    "\t\tif image_id not in mapping:\n",
    "\t\t\tmapping[image_id] = list()\n",
    "\t\t# store description\n",
    "\t\tmapping[image_id].append(image_desc)\n",
    "\treturn mapping\n",
    "\n",
    "\n",
    "# parse descriptions\n",
    "descriptions = load_descriptions(doc)\n",
    "\n",
    "\n",
    "def clean_descriptions(descriptions):\n",
    "\t# prepare translation table for removing punctuation\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor key, desc_list in descriptions.items():\n",
    "\t\tfor i in range(len(desc_list)):\n",
    "\t\t\tdesc = desc_list[i]\n",
    "\t\t\t# tokenize\n",
    "\t\t\tdesc = desc.split()\n",
    "\t\t\t# convert to lower case\n",
    "\t\t\tdesc = [word.lower() for word in desc]\n",
    "\t\t\t# remove punctuation from each token\n",
    "\t\t\tdesc = [w.translate(table) for w in desc]\n",
    "\t\t\t# remove hanging 's' and 'a'\n",
    "\t\t\tdesc = [word for word in desc if len(word)>1]\n",
    "\t\t\t# remove tokens with numbers in them\n",
    "\t\t\tdesc = [word for word in desc if word.isalpha()]\n",
    "\t\t\t# store as string\n",
    "\t\t\tdesc_list[i] = ' '.join(desc)\n",
    "\n",
    "\n",
    "# clean descriptions\n",
    "clean_descriptions(descriptions)\n",
    "\n",
    "# load a pre-defined list of photo identifiers\n",
    "def load_set(filename):\n",
    "\tdoc = load_doc(filename)\n",
    "\tdataset = list()\n",
    "\t# process line by line\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# skip empty lines\n",
    "\t\tif len(line) < 1:\n",
    "\t\t\tcontinue\n",
    "\t\t# get the image identifier\n",
    "\t\tidentifier = line.split('.')[0]\n",
    "\t\tdataset.append(identifier)\n",
    "\treturn set(dataset)\n",
    "\n",
    "\n",
    "filename = 'C:/Users/Laxmi/Desktop/Flickr Dataset/Flickr dataset/Flickr_8k.trainImages.txt'\n",
    "train = load_set(filename)\n",
    "\n",
    "\n",
    "# load clean descriptions into memory\n",
    "def load_clean_descriptions(filename, dataset):\n",
    "\t# load document\n",
    "\tdoc = load_doc(filename)\n",
    "\tdescriptions = dict()\n",
    "\tfor line in doc.split('\\n'):\n",
    "\t\t# split line by white space\n",
    "\t\ttokens = line.split()\n",
    "\t\t# split id from description\n",
    "\t\timage_id, image_desc = tokens[0], tokens[1:]\n",
    "\t\t# skip images not in the set\n",
    "\t\tif image_id in dataset:\n",
    "\t\t\t# create list\n",
    "\t\t\tif image_id not in descriptions:\n",
    "\t\t\t\tdescriptions[image_id] = list()\n",
    "\t\t\t# wrap description in tokens\n",
    "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "\t\t\t# store\n",
    "\t\t\tdescriptions[image_id].append(desc)\n",
    "\treturn descriptions\n",
    "\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_clean_descriptions('C:/Users/Laxmi/Desktop/Flickr Dataset/Flickr dataset/descriptions.txt', train)\n",
    "\n",
    "all_train_captions = []\n",
    "for key, val in train_descriptions.items():\n",
    "\tfor cap in val:\n",
    "\t\tall_train_captions.append(cap)\n",
    "\n",
    "word_count_threshold = 10\n",
    "word_counts = {}\n",
    "nsents = 0\n",
    "for sent in all_train_captions:\n",
    "\tnsents += 1\n",
    "\tfor w in sent.split(' '):\n",
    "\t\tword_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "\n",
    "ixtoword = {}\n",
    "wordtoix = {}\n",
    "\n",
    "ix = 1\n",
    "for w in vocab:\n",
    "\twordtoix[w] = ix\n",
    "\tixtoword[ix] = w\n",
    "\tix += 1\n",
    "\n",
    "\n",
    "def greedySearch(photo, model):\n",
    "    in_text = 'startseq'        \n",
    "    for i in range(max_length):\n",
    "        sequence = [wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        photo = np.resize(photo, (1,2048))\n",
    "        yhat = model.predict([photo,sequence], verbose=0)        \n",
    "        yhat = np.argmax(yhat)\n",
    "        word = ixtoword[yhat]\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    final = in_text.split()\n",
    "    final = final[1:-1]\n",
    "    final = ' '.join(final)\n",
    "    return final\n",
    "\n",
    "def get_predictions():\n",
    "    model = tf.keras.models.load_model('C:/Users/Laxmi/Desktop/Image captioning/model_4.h5')\n",
    "# model.load_weights('C:/Users/Laxmi/Desktop/Image captioning/model_4.h5')\n",
    "\n",
    "    images = 'C:/Users/Laxmi/Desktop/Flickr Dataset/Flicker8k_Dataset_Image/'\n",
    "    with open(\"C:/Users/Laxmi/Desktop/Flickr Dataset/Flickr dataset/encoded_test_images.pkl\", \"rb\") as encoded_pickle:\n",
    "        encoding_test = load(encoded_pickle)\n",
    "    index = np.random.choice(1000)\n",
    "    pic = list(encoding_test.keys())[index] \n",
    "    image = encoding_test[pic].reshape((1,2048))\n",
    "    x=plt.imread(images+pic)\n",
    "    st.sidebar.image(x,use_column_width=True)  \n",
    "    caption=greedySearch(image,model)\n",
    "    st.write('## Caption Generated is: ')\n",
    "    st.write(caption)\n",
    "\n",
    "st.title('Image caption generator')\n",
    "# if st.button('Generate a Random Image'):\n",
    "\n",
    "st.sidebar.markdown('## Input Image')\n",
    "if st.button('Generate a Random Image'):\n",
    "    get_predictions()\n",
    "\n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
